{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "368f8e96",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores for Random Forest: [0.76 0.84 0.72 0.84 0.75]\n",
      "\n",
      "Model Comparison:\n",
      "\n",
      "Dynamic Bagging (SVM) - Accuracy: 71.88%, Precision: 83.33%, Recall: 71.43%, F1 Score: 76.92%\n",
      "Dynamic Bagging (Random Forest) - Accuracy: 78.12%, Precision: 100.00%, Recall: 66.67%, F1 Score: 80.00%\n",
      "AdaBoost - Accuracy: 75.00%, Precision: 93.33%, Recall: 66.67%, F1 Score: 77.78%\n",
      "Gradient Boosting - Accuracy: 78.12%, Precision: 93.75%, Recall: 71.43%, F1 Score: 81.08%\n",
      "Extra Trees - Accuracy: 75.00%, Precision: 84.21%, Recall: 76.19%, F1 Score: 80.00%\n",
      "Hybrid Voting - Accuracy: 78.12%, Precision: 93.75%, Recall: 71.43%, F1 Score: 81.08%\n",
      "Stacking Ensemble - Accuracy: 81.25%, Precision: 94.12%, Recall: 76.19%, F1 Score: 84.21%\n",
      "\n",
      "Please enter the following details to predict your CGPA:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Student Age (1: 18-21, 2: 22-25, 3: above 26):  1\n",
      "Sex (1: female, 2: male):  2\n",
      "High School Type (1: private, 2: state, 3: other):  1\n",
      "Scholarship (1: None, 2: 25%, 3: 50%, 4: 75%, 5: Full):  2\n",
      "Additional Work (1: Yes, 2: No):  1\n",
      "Artistic/Sports Activity (1: Yes, 2: No):  2\n",
      "Partner (1: Yes, 2: No):  1\n",
      "Total Salary (1: 135-200, 2: 201-270, 3: 271-340, 4: 341-410, 5: above 410):  1\n",
      "Transportation (1: Bus, 2: Car/Taxi, 3: Bicycle, 4: Other):  1\n",
      "Accommodation (1: Rental, 2: Dormitory, 3: Family, 4: Other):  1\n",
      "Mother's Education (1: primary, 2: secondary, 3: high school, 4: university, 5: MSc, 6: PhD):  1\n",
      "Father's Education (1: primary, 2: secondary, 3: high school, 4: university, 5: MSc, 6: PhD):  2\n",
      "Siblings (1: 1, 2: 2, 3: 3, 4: 4, 5: 5+):  3\n",
      "Parental Status (1: married, 2: divorced, 3: died):  2\n",
      "Mother's Occupation (1: retired, 2: housewife, 3: gov. officer, 4: private, 5: self-employed, 6: other):  5\n",
      "Father's Occupation (1: retired, 2: gov. officer, 3: private, 4: self-employed, 5: other):  5\n",
      "Weekly Study Hours (1: None, 2: <5, 3: 6-10, 4: 11-20, 5: >20):  4\n",
      "Non-Scientific Reading (1: None, 2: Sometimes, 3: Often):  2\n",
      "Scientific Reading (1: None, 2: Sometimes, 3: Often):  2\n",
      "Seminar Attendance (1: Yes, 2: No):  2\n",
      "Impact of Projects (1: positive, 2: negative, 3: neutral):  1\n",
      "Class Attendance (1: always, 2: sometimes, 3: never):  2\n",
      "Midterm 1 Prep (1: alone, 2: friends, 3: n/a):  1\n",
      "Midterm 2 Prep (1: close to exam, 2: regular, 3: never):  2\n",
      "Taking Notes (1: never, 2: sometimes, 3: always):  3\n",
      "Listening in Class (1: never, 2: sometimes, 3: always):  3\n",
      "Discussion Improves Success (1: never, 2: sometimes, 3: always):  3\n",
      "Flip-Classroom (1: not useful, 2: useful, 3: n/a):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction: Fail\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import (RandomForestClassifier, BaggingClassifier, AdaBoostClassifier,\n",
    "                              GradientBoostingClassifier, VotingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load and Preprocess Data\n",
    "data = pd.read_csv('StudentsPerformance_with_headers.csv')\n",
    "label_encoder = LabelEncoder()\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Define target and features\n",
    "X = data.drop(columns=['GRADE'])\n",
    "y = data['GRADE'].apply(lambda x: 1 if x > 2 else 0)\n",
    "\n",
    "# Balance dataset with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Hyperparameter tuning for SVM, RandomForest, and XGBoost using GridSearchCV\n",
    "param_grid_svm = {'C': [0.1, 0.5, 1], 'gamma': [0.001, 0.01, 0.1], 'kernel': ['linear', 'rbf']}\n",
    "svm_tuned = GridSearchCV(SVC(probability=True), param_grid_svm, cv=5)\n",
    "svm_tuned.fit(X_train, y_train)\n",
    "\n",
    "param_grid_rf = {'n_estimators': [100, 200], 'max_depth': [10, 15], 'min_samples_split': [2, 5]}\n",
    "rf_tuned = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv=5)\n",
    "rf_tuned.fit(X_train, y_train)\n",
    "\n",
    "param_grid_xgb = {'n_estimators': [100, 150], 'max_depth': [6, 8], 'learning_rate': [0.01, 0.05, 0.1]}\n",
    "xgb_tuned = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'), param_grid_xgb, cv=5)\n",
    "xgb_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Cross-validation example\n",
    "cv_scores = cross_val_score(rf_tuned.best_estimator_, X_train, y_train, cv=5)\n",
    "print(\"Cross-validation scores for Random Forest:\", cv_scores)\n",
    "\n",
    "# Models and Ensembles with hyperparameter tuning\n",
    "\n",
    "# Dynamic Bagging using BaggingClassifier with tuned SVM and RandomForest as base estimators\n",
    "dynamic_bagging_svm = BaggingClassifier(estimator=svm_tuned.best_estimator_, n_estimators=10, random_state=42)\n",
    "dynamic_bagging_svm.fit(X_train, y_train)\n",
    "dynamic_bagging_svm_metrics = evaluate_model(dynamic_bagging_svm, X_test, y_test)\n",
    "\n",
    "dynamic_bagging_rf = BaggingClassifier(estimator=rf_tuned.best_estimator_, n_estimators=10, random_state=42)\n",
    "dynamic_bagging_rf.fit(X_train, y_train)\n",
    "dynamic_bagging_rf_metrics = evaluate_model(dynamic_bagging_rf, X_test, y_test)\n",
    "\n",
    "# AdaBoost with Decision Tree as base estimator\n",
    "ada_boost = AdaBoostClassifier(estimator=RandomForestClassifier(max_depth=1), n_estimators=50, learning_rate=0.5, random_state=42)\n",
    "ada_boost.fit(X_train, y_train)\n",
    "ada_boost_metrics = evaluate_model(ada_boost, X_test, y_test)\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gradient_boosting = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "gradient_boosting_metrics = evaluate_model(gradient_boosting, X_test, y_test)\n",
    "\n",
    "# Extra Trees (Another bagging method) \n",
    "extra_trees = ExtraTreesClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "extra_trees_metrics = evaluate_model(extra_trees, X_test, y_test)\n",
    "\n",
    "# Hybrid Voting Ensemble with tuned estimators\n",
    "voting_ensemble_tuned = VotingClassifier(estimators=[\n",
    "    ('SVM', svm_tuned.best_estimator_), ('RandomForest', rf_tuned.best_estimator_), ('XGBoost', xgb_tuned.best_estimator_),\n",
    "    ('Dynamic_Bagging_RF', dynamic_bagging_rf), ('Dynamic_Bagging_SVM', dynamic_bagging_svm),\n",
    "    ('AdaBoost', ada_boost), ('GradientBoosting', gradient_boosting), ('ExtraTrees', extra_trees)],\n",
    "    voting='soft')\n",
    "voting_ensemble_tuned.fit(X_train, y_train)\n",
    "voting_ensemble_tuned_metrics = evaluate_model(voting_ensemble_tuned, X_test, y_test)\n",
    "\n",
    "# Stacking Ensemble with Logistic Regression as final estimator\n",
    "stacking_ensemble = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('RandomForest', rf_tuned.best_estimator_), ('XGBoost', xgb_tuned.best_estimator_), ('GradientBoosting', gradient_boosting)],\n",
    "    final_estimator=LogisticRegression())\n",
    "stacking_ensemble.fit(X_train, y_train)\n",
    "stacking_ensemble_metrics = evaluate_model(stacking_ensemble, X_test, y_test)\n",
    "\n",
    "# Display Model Comparison\n",
    "model_names = [\n",
    "    \"Dynamic Bagging (SVM)\", \"Dynamic Bagging (Random Forest)\", \"AdaBoost\", \n",
    "    \"Gradient Boosting\", \"Extra Trees\", \"Hybrid Voting\", \"Stacking Ensemble\"\n",
    "]\n",
    "model_metrics = [\n",
    "    dynamic_bagging_svm_metrics, dynamic_bagging_rf_metrics, ada_boost_metrics, \n",
    "    gradient_boosting_metrics, extra_trees_metrics, voting_ensemble_tuned_metrics, stacking_ensemble_metrics\n",
    "]\n",
    "\n",
    "print(\"\\nModel Comparison:\\n\")\n",
    "for name, metrics in zip(model_names, model_metrics):\n",
    "    accuracy, precision, recall, f1 = metrics\n",
    "    print(f\"{name} - Accuracy: {accuracy*100:.2f}%, Precision: {precision*100:.2f}%, Recall: {recall*100:.2f}%, F1 Score: {f1*100:.2f}%\")\n",
    "\n",
    "# Function for collecting user input and making predictions\n",
    "def user_predict_cgpa(model, scaler):\n",
    "    print(\"\\nPlease enter the following details to predict your CGPA:\")\n",
    "    \n",
    "    user_data = {\n",
    "'Student Age': int(input(\"Student Age (1: 18-21, 2: 22-25, 3: above 26): \")),\n",
    "        'Sex': int(input(\"Sex (1: female, 2: male): \")),\n",
    "        'High School Type': int(input(\"High School Type (1: private, 2: state, 3: other): \")),\n",
    "        'Scholarship': int(input(\"Scholarship (1: None, 2: 25%, 3: 50%, 4: 75%, 5: Full): \")),\n",
    "        'Additional Work': int(input(\"Additional Work (1: Yes, 2: No): \")),\n",
    "        'Artistic/Sports Activity': int(input(\"Artistic/Sports Activity (1: Yes, 2: No): \")),\n",
    "        'Partner': int(input(\"Partner (1: Yes, 2: No): \")),\n",
    "        'Total Salary': int(input(\"Total Salary (1: 135-200, 2: 201-270, 3: 271-340, 4: 341-410, 5: above 410): \")),\n",
    "        'Transportation': int(input(\"Transportation (1: Bus, 2: Car/Taxi, 3: Bicycle, 4: Other): \")),\n",
    "        'Accommodation': int(input(\"Accommodation (1: Rental, 2: Dormitory, 3: Family, 4: Other): \")),\n",
    "        'Mother’s Education': int(input(\"Mother's Education (1: primary, 2: secondary, 3: high school, 4: university, 5: MSc, 6: PhD): \")),\n",
    "        'Father’s Education': int(input(\"Father's Education (1: primary, 2: secondary, 3: high school, 4: university, 5: MSc, 6: PhD): \")),\n",
    "        'Siblings': int(input(\"Siblings (1: 1, 2: 2, 3: 3, 4: 4, 5: 5+): \")),\n",
    "        'Parental Status': int(input(\"Parental Status (1: married, 2: divorced, 3: died): \")),\n",
    "        'Mother’s Occupation': int(input(\"Mother's Occupation (1: retired, 2: housewife, 3: gov. officer, 4: private, 5: self-employed, 6: other): \")),\n",
    "        'Father’s Occupation': int(input(\"Father's Occupation (1: retired, 2: gov. officer, 3: private, 4: self-employed, 5: other): \")),\n",
    "        'Weekly Study Hours': int(input(\"Weekly Study Hours (1: None, 2: <5, 3: 6-10, 4: 11-20, 5: >20): \")),\n",
    "        'Non-Scientific Reading': int(input(\"Non-Scientific Reading (1: None, 2: Sometimes, 3: Often): \")),\n",
    "        'Scientific Reading': int(input(\"Scientific Reading (1: None, 2: Sometimes, 3: Often): \")),\n",
    "        'Seminar Attendance': int(input(\"Seminar Attendance (1: Yes, 2: No): \")),\n",
    "        'Impact of Projects': int(input(\"Impact of Projects (1: positive, 2: negative, 3: neutral): \")),\n",
    "        'Class Attendance': int(input(\"Class Attendance (1: always, 2: sometimes, 3: never): \")),\n",
    "        'Midterm 1 Prep': int(input(\"Midterm 1 Prep (1: alone, 2: friends, 3: n/a): \")),\n",
    "        'Midterm 2 Prep': int(input(\"Midterm 2 Prep (1: close to exam, 2: regular, 3: never): \")),\n",
    "        'Taking Notes': int(input(\"Taking Notes (1: never, 2: sometimes, 3: always): \")),\n",
    "        'Listening in Class': int(input(\"Listening in Class (1: never, 2: sometimes, 3: always): \")),\n",
    "        'Discussion Improves Success': int(input(\"Discussion Improves Success (1: never, 2: sometimes, 3: always): \")),\n",
    "        'Flip-Classroom': int(input(\"Flip-Classroom (1: not useful, 2: useful, 3: n/a): \")),\n",
    "    }\n",
    "\n",
    "    user_input_df = pd.DataFrame([user_data])\n",
    "    missing_cols = [col for col in X.columns if col not in user_input_df.columns]\n",
    "    for col in missing_cols:\n",
    "        user_input_df[col] = 0\n",
    "    user_input_df = user_input_df[X.columns]\n",
    "\n",
    "    user_input_scaled = scaler.transform(user_input_df)\n",
    "    prediction = model.predict(user_input_scaled)\n",
    "    if prediction == 1:\n",
    "        print(\"\\nPrediction: Pass\")\n",
    "    else:\n",
    "        print(\"\\nPrediction: Fail\")\n",
    "\n",
    "# Use the chosen model for final user prediction\n",
    "user_predict_cgpa(voting_ensemble_tuned, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cedab3-761b-4c92-9da8-929dfaa153f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
