{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f8e96",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine (SVM):\n",
      "Accuracy: 92.73%\n",
      "Precision: 96.15%\n",
      "Recall: 89.29%\n",
      "F1 Score: 92.59%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        27\n",
      "           1       0.96      0.89      0.93        28\n",
      "\n",
      "    accuracy                           0.93        55\n",
      "   macro avg       0.93      0.93      0.93        55\n",
      "weighted avg       0.93      0.93      0.93        55\n",
      "\n",
      "Confusion Matrix:\n",
      " [[26  1]\n",
      " [ 3 25]]\n",
      "\n",
      "Random Forest Classifier:\n",
      "Accuracy: 98.18%\n",
      "Precision: 100.00%\n",
      "Recall: 96.43%\n",
      "F1 Score: 98.18%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        27\n",
      "           1       1.00      0.96      0.98        28\n",
      "\n",
      "    accuracy                           0.98        55\n",
      "   macro avg       0.98      0.98      0.98        55\n",
      "weighted avg       0.98      0.98      0.98        55\n",
      "\n",
      "Confusion Matrix:\n",
      " [[27  0]\n",
      " [ 1 27]]\n",
      "\n",
      "XGBoost Classifier:\n",
      "Accuracy: 94.55%\n",
      "Precision: 100.00%\n",
      "Recall: 89.29%\n",
      "F1 Score: 94.34%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        27\n",
      "           1       1.00      0.89      0.94        28\n",
      "\n",
      "    accuracy                           0.95        55\n",
      "   macro avg       0.95      0.95      0.95        55\n",
      "weighted avg       0.95      0.95      0.95        55\n",
      "\n",
      "Confusion Matrix:\n",
      " [[27  0]\n",
      " [ 3 25]]\n",
      "\n",
      "Please enter the following details to predict your CGPA:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Age (1: 18-21, 2: 22-25, 3: above 26):  1\n",
      "Sex (1: female, 2: male):  1\n",
      "High School Type (1: private, 2: state, 3: other):  1\n",
      "Scholarship (1: None, 2: 25%, 3: 50%, 4: 75%, 5: Full):  1\n",
      "Additional Work (1: Yes, 2: No):  1\n",
      "Artistic/Sports Activity (1: Yes, 2: No):  1\n",
      "Partner (1: Yes, 2: No):  1\n",
      "Total Salary (1: 135-200, 2: 201-270, 3: 271-340, 4: 341-410, 5: above 410):  1\n",
      "Transportation (1: Bus, 2: Car/Taxi, 3: Bicycle, 4: Other):  1\n",
      "Accommodation (1: Rental, 2: Dormitory, 3: Family, 4: Other):  1\n",
      "Mother's Education (1: primary, 2: secondary, 3: high school, 4: university, 5: MSc, 6: PhD):  2\n",
      "Father's Education (1: primary, 2: secondary, 3: high school, 4: university, 5: MSc, 6: PhD):  2\n",
      "Siblings (1: 1, 2: 2, 3: 3, 4: 4, 5: 5+):  2\n",
      "Parental Status (1: married, 2: divorced, 3: died):  1\n",
      "Mother's Occupation (1: retired, 2: housewife, 3: gov. officer, 4: private, 5: self-employed, 6: other):  3\n",
      "Father's Occupation (1: retired, 2: gov. officer, 3: private, 4: self-employed, 5: other):  3\n",
      "Weekly Study Hours (1: None, 2: <5, 3: 6-10, 4: 11-20, 5: >20):  2\n",
      "Non-Scientific Reading (1: None, 2: Sometimes, 3: Often):  2\n",
      "Scientific Reading (1: None, 2: Sometimes, 3: Often):  2\n",
      "Seminar Attendance (1: Yes, 2: No):  1\n",
      "Impact of Projects (1: positive, 2: negative, 3: neutral):  1\n",
      "Class Attendance (1: always, 2: sometimes, 3: never):  2\n",
      "Midterm 1 Prep (1: alone, 2: friends, 3: n/a):  2\n",
      "Midterm 2 Prep (1: close to exam, 2: regular, 3: never):  1\n",
      "Taking Notes (1: never, 2: sometimes, 3: always):  2\n",
      "Listening in Class (1: never, 2: sometimes, 3: always):  2\n",
      "Discussion Improves Success (1: never, 2: sometimes, 3: always):  2\n",
      "Flip-Classroom (1: not useful, 2: useful, 3: n/a):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted CGPA Category: Fail\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import (RandomForestClassifier, BaggingClassifier, AdaBoostClassifier,\n",
    "                              GradientBoostingClassifier, VotingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load and Preprocess Data\n",
    "data = pd.read_csv('StudentsPerformance_with_headers.csv')\n",
    "label_encoder = LabelEncoder()\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Define target and features\n",
    "X = data.drop(columns=['GRADE'])\n",
    "y = data['GRADE'].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "# Balance dataset with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Models and Ensembles\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "svm = SVC(kernel='linear', C=0.5, gamma=0.01, probability=True)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_metrics = evaluate_model(svm, X_test, y_test)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_metrics = evaluate_model(rf, X_test, y_test)\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(n_estimators=150, max_depth=8, learning_rate=0.03, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_metrics = evaluate_model(xgb, X_test, y_test)\n",
    "\n",
    "# Bagging with RandomForest as base estimator\n",
    "bagging_rf = BaggingClassifier(base_estimator=RandomForestClassifier(), n_estimators=10, random_state=42)\n",
    "bagging_rf.fit(X_train, y_train)\n",
    "bagging_rf_metrics = evaluate_model(bagging_rf, X_test, y_test)\n",
    "\n",
    "# Bagging with SVM as base estimator\n",
    "bagging_svm = BaggingClassifier(base_estimator=SVC(kernel='linear', C=0.5, gamma=0.01, probability=True), n_estimators=10, random_state=42)\n",
    "bagging_svm.fit(X_train, y_train)\n",
    "bagging_svm_metrics = evaluate_model(bagging_svm, X_test, y_test)\n",
    "\n",
    "# Extra Trees (Another bagging method)\n",
    "extra_trees = ExtraTreesClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "extra_trees_metrics = evaluate_model(extra_trees, X_test, y_test)\n",
    "\n",
    "# AdaBoost with Decision Tree as base estimator\n",
    "ada_boost = AdaBoostClassifier(base_estimator=RandomForestClassifier(max_depth=1), n_estimators=50, learning_rate=0.5, random_state=42)\n",
    "ada_boost.fit(X_train, y_train)\n",
    "ada_boost_metrics = evaluate_model(ada_boost, X_test, y_test)\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gradient_boosting = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "gradient_boosting_metrics = evaluate_model(gradient_boosting, X_test, y_test)\n",
    "\n",
    "# Hybrid Voting Ensemble (Soft Voting)\n",
    "voting_ensemble = VotingClassifier(estimators=[\n",
    "    ('SVM', svm), ('RandomForest', rf), ('XGBoost', xgb),\n",
    "    ('Bagging_RF', bagging_rf), ('Bagging_SVM', bagging_svm), ('AdaBoost', ada_boost), ('GradientBoosting', gradient_boosting)],\n",
    "    voting='soft')\n",
    "voting_ensemble.fit(X_train, y_train)\n",
    "voting_ensemble_metrics = evaluate_model(voting_ensemble, X_test, y_test)\n",
    "\n",
    "# Stacking Ensemble with Logistic Regression as final estimator\n",
    "stacking_ensemble = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('RandomForest', rf), ('XGBoost', xgb), ('GradientBoosting', gradient_boosting)],\n",
    "    final_estimator=LogisticRegression())\n",
    "stacking_ensemble.fit(X_train, y_train)\n",
    "stacking_ensemble_metrics = evaluate_model(stacking_ensemble, X_test, y_test)\n",
    "\n",
    "# Display Model Comparison\n",
    "model_names = [\n",
    "    \"SVM\", \"Random Forest\", \"XGBoost\", \"Bagging (Random Forest)\",\n",
    "    \"Bagging (SVM)\", \"Extra Trees\", \"AdaBoost\", \"Gradient Boosting\", \n",
    "    \"Hybrid Voting\", \"Stacking Ensemble\"\n",
    "]\n",
    "model_metrics = [\n",
    "    svm_metrics, rf_metrics, xgb_metrics, bagging_rf_metrics,\n",
    "    bagging_svm_metrics, extra_trees_metrics, ada_boost_metrics, gradient_boosting_metrics,\n",
    "    voting_ensemble_metrics, stacking_ensemble_metrics\n",
    "]\n",
    "\n",
    "print(\"\\nModel Comparison:\\n\")\n",
    "for name, metrics in zip(model_names, model_metrics):\n",
    "    accuracy, precision, recall, f1 = metrics\n",
    "    print(f\"{name} - Accuracy: {accuracy*100:.2f}%, Precision: {precision*100:.2f}%, Recall: {recall*100:.2f}%, F1 Score: {f1*100:.2f}%\")\n",
    "\n",
    "# User Input Function for Prediction\n",
    "def user_predict_cgpa(model, scaler):\n",
    "    print(\"\\nPlease enter the following details to predict your CGPA:\")\n",
    "    \n",
    "    user_data = {\n",
    "        'Student Age': int(input(\"Student Age (1: 18-21, 2: 22-25, 3: above 26): \")),\n",
    "        'Sex': int(input(\"Sex (1: female, 2: male): \")),\n",
    "        'Graduated high-school type': int(input(\"High School Type (1: private, 2: state, 3: other): \")),\n",
    "        'Scholarship type': int(input(\"Scholarship (1: None, 2: 25%, 3: 50%, 4: 75%, 5: Full): \")),\n",
    "        'Additional work': int(input(\"Additional Work (1: Yes, 2: No): \")),\n",
    "        'Regular artistic or sports activity': int(input(\"Artistic/Sports Activity (1: Yes, 2: No): \")),\n",
    "        'Do you have a partner': int(input(\"Partner (1: Yes, 2: No): \")),\n",
    "        'Total salary if available': int(input(\"Total Salary (1: 135-200, 2: 201-270, 3: 271-340, 4: 341-410, 5: above 410): \")),\n",
    "        'Transportation to the university': int(input(\"Transportation (1: Bus, 2: Car/Taxi, 3: Bicycle, 4: Other): \")),\n",
    "        'Accommodation type in Cyprus': int(input(\"Accommodation (1: Rental, 2: Dormitory, 3: Family, 4: Other): \")),\n",
    "        'Mother’s education': int(input(\"Mother's Education (1: primary, 2: secondary, 3: high school, 4: university, 5: MSc, 6: PhD): \")),\n",
    "        'Father’s education': int(input(\"Father's Education (1: primary, 2: secondary, 3: high school, 4: university, 5: MSc, 6: PhD): \")),\n",
    "        'Number of sisters/brothers': int(input(\"Siblings (1: 1, 2: 2, 3: 3, 4: 4, 5: 5+): \")),\n",
    "        'Parental status': int(input(\"Parental Status (1: married, 2: divorced, 3: died): \")),\n",
    "        'Mother’s occupation': int(input(\"Mother's Occupation (1: retired, 2: housewife, 3: gov. officer, 4: private, 5: self-employed, 6: other): \")),\n",
    "        'Father’s occupation': int(input(\"Father's Occupation (1: retired, 2: gov. officer, 3: private, 4: self-employed, 5: other): \")),\n",
    "        'Weekly study hours': int(input(\"Weekly Study Hours (1: None, 2: <5, 3: 6-10, 4: 11-20, 5: >20): \")),\n",
    "        'Reading frequency (non-academic)': int(input(\"Reading Frequency (1: Never, 2: Sometimes, 3: Often): \")),\n",
    "        'Attendance to seminars/conferences': int(input(\"Seminars/Conferences (1: Never, 2: Sometimes, 3: Always): \")),\n",
    "        'Impact of additional activities on success': int(input(\"Impact of Activities (1: negative, 2: neutral, 3: positive): \")),\n",
    "        'Class Teacher Interactions': int(input(\"Teacher Interaction (1: never, 2: sometimes, 3: always): \"))\n",
    "    }\n",
    "    \n",
    "    user_input = np.array(list(user_data.values())).reshape(1, -1)\n",
    "    user_input_scaled = scaler.transform(user_input)\n",
    "    prediction = model.predict(user_input_scaled)\n",
    "    \n",
    "    if prediction[0] == 1:\n",
    "        print(\"\\nPrediction: Pass\")\n",
    "    else:\n",
    "        print(\"\\nPrediction: Fail\")\n",
    "\n",
    "# Use Hybrid Voting Model for final user prediction\n",
    "user_predict_cgpa(voting_ensemble, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cedab3-761b-4c92-9da8-929dfaa153f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
