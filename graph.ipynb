{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc395f7c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "svm_metrics = {'accuracy': 0.9273, 'precision': 0.9615, 'recall': 0.8929}\n",
    "rf_metrics = {'accuracy': 0.9818, 'precision': 1, 'recall': 0.9643}\n",
    "xgb_metrics = {'accuracy': 0.9455, 'precision': 1, 'recall': 0.8929}\n",
    "\n",
    "# Extract metric values for plotting\n",
    "metrics = list(svm_metrics.keys())\n",
    "svm_values = list(svm_metrics.values())\n",
    "rf_values = list(rf_metrics.values())\n",
    "xgb_values = list(xgb_metrics.values())\n",
    "\n",
    "# Plotting the metrics for each model\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(metrics, svm_values, marker='o', label='SVM', color='skyblue', linestyle='-', linewidth=2)\n",
    "plt.plot(metrics, rf_values, marker='s', label='Random Forest', color='lightgreen', linestyle='-', linewidth=2)\n",
    "plt.plot(metrics, xgb_values, marker='^', label='XGBoost', color='salmon', linestyle='-', linewidth=2)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Performance Comparison Across Metrics')\n",
    "plt.ylim([0, 1])  # Ensures the y-axis goes from 0 to 1 for consistency\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Adding grid for readability\n",
    "plt.grid(visible=True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
