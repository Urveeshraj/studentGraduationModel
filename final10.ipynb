{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f8e96",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison:\n",
      "\n",
      "SVM - Accuracy: 75.00%, Precision: 93.33%, Recall: 66.67%, F1 Score: 77.78%\n",
      "Random Forest - Accuracy: 75.00%, Precision: 93.33%, Recall: 66.67%, F1 Score: 77.78%\n",
      "XGBoost - Accuracy: 81.25%, Precision: 94.12%, Recall: 76.19%, F1 Score: 84.21%\n",
      "Bagging (Random Forest) - Accuracy: 78.12%, Precision: 100.00%, Recall: 66.67%, F1 Score: 80.00%\n",
      "Bagging (SVM) - Accuracy: 75.00%, Precision: 93.33%, Recall: 66.67%, F1 Score: 77.78%\n",
      "Extra Trees - Accuracy: 75.00%, Precision: 84.21%, Recall: 76.19%, F1 Score: 80.00%\n",
      "AdaBoost - Accuracy: 75.00%, Precision: 93.33%, Recall: 66.67%, F1 Score: 77.78%\n",
      "Gradient Boosting - Accuracy: 78.12%, Precision: 93.75%, Recall: 71.43%, F1 Score: 81.08%\n",
      "Hybrid Voting - Accuracy: 78.12%, Precision: 93.75%, Recall: 71.43%, F1 Score: 81.08%\n",
      "Stacking Ensemble - Accuracy: 81.25%, Precision: 94.12%, Recall: 76.19%, F1 Score: 84.21%\n",
      "\n",
      "Please enter the following details to predict your CGPA:\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import (RandomForestClassifier, BaggingClassifier, AdaBoostClassifier,\n",
    "                              GradientBoostingClassifier, VotingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load and Preprocess Data\n",
    "data = pd.read_csv('StudentsPerformance_with_headers.csv')\n",
    "label_encoder = LabelEncoder()\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    data[column] = label_encoder.fit_transform(data[column])\n",
    "\n",
    "# Define target and features\n",
    "X = data.drop(columns=['GRADE'])\n",
    "y = data['GRADE'].apply(lambda x: 1 if x > 2 else 0)\n",
    "\n",
    "# Balance dataset with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Evaluation Function\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Models and Ensembles\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "svm = SVC(kernel='linear', C=0.5, gamma=0.01, probability=True)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_metrics = evaluate_model(svm, X_test, y_test)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_metrics = evaluate_model(rf, X_test, y_test)\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(n_estimators=150, max_depth=8, learning_rate=0.03, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_metrics = evaluate_model(xgb, X_test, y_test)\n",
    "\n",
    "# Bagging with RandomForest as base estimator\n",
    "bagging_rf = BaggingClassifier(estimator=RandomForestClassifier(), n_estimators=10, random_state=42)\n",
    "bagging_rf.fit(X_train, y_train)\n",
    "bagging_rf_metrics = evaluate_model(bagging_rf, X_test, y_test)\n",
    "\n",
    "# Bagging with SVM as base estimator i\n",
    "bagging_svm = BaggingClassifier(estimator=SVC(kernel='linear', C=0.5, gamma=0.01, probability=True), n_estimators=10, random_state=42)\n",
    "bagging_svm.fit(X_train, y_train)\n",
    "bagging_svm_metrics = evaluate_model(bagging_svm, X_test, y_test)\n",
    "\n",
    "\n",
    "# Extra Trees (Another bagging method) \n",
    "extra_trees = ExtraTreesClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "extra_trees.fit(X_train, y_train)\n",
    "extra_trees_metrics = evaluate_model(extra_trees, X_test, y_test)\n",
    "\n",
    "# AdaBoost with Decision Tree as base estimator i\n",
    "ada_boost = AdaBoostClassifier(estimator=RandomForestClassifier(max_depth=1), n_estimators=50, learning_rate=0.5, random_state=42)\n",
    "ada_boost.fit(X_train, y_train)\n",
    "ada_boost_metrics = evaluate_model(ada_boost, X_test, y_test)\n",
    "\n",
    "\n",
    "# Gradient Boosting Classifier\n",
    "gradient_boosting = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "gradient_boosting_metrics = evaluate_model(gradient_boosting, X_test, y_test)\n",
    "\n",
    "# Hybrid Voting Ensemble (Soft Voting)\n",
    "voting_ensemble = VotingClassifier(estimators=[\n",
    "    ('SVM', svm), ('RandomForest', rf), ('XGBoost', xgb),\n",
    "    ('Bagging_RF', bagging_rf), ('Bagging_SVM', bagging_svm), ('AdaBoost', ada_boost), ('GradientBoosting', gradient_boosting)],\n",
    "    voting='soft')\n",
    "voting_ensemble.fit(X_train, y_train)\n",
    "voting_ensemble_metrics = evaluate_model(voting_ensemble, X_test, y_test)\n",
    "\n",
    "# Stacking Ensemble with Logistic Regression as final estimator\n",
    "stacking_ensemble = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('RandomForest', rf), ('XGBoost', xgb), ('GradientBoosting', gradient_boosting)],\n",
    "    final_estimator=LogisticRegression())\n",
    "stacking_ensemble.fit(X_train, y_train)\n",
    "stacking_ensemble_metrics = evaluate_model(stacking_ensemble, X_test, y_test)\n",
    "\n",
    "# Display Model Comparison\n",
    "model_names = [\n",
    "    \"SVM\", \"Random Forest\", \"XGBoost\", \"Bagging (Random Forest)\",\n",
    "    \"Bagging (SVM)\", \"Extra Trees\", \"AdaBoost\", \"Gradient Boosting\", \n",
    "    \"Hybrid Voting\", \"Stacking Ensemble\"\n",
    "]\n",
    "model_metrics = [\n",
    "    svm_metrics, rf_metrics, xgb_metrics, bagging_rf_metrics,\n",
    "    bagging_svm_metrics, extra_trees_metrics, ada_boost_metrics, gradient_boosting_metrics,\n",
    "    voting_ensemble_metrics, stacking_ensemble_metrics\n",
    "]\n",
    "\n",
    "print(\"\\nModel Comparison:\\n\")\n",
    "for name, metrics in zip(model_names, model_metrics):\n",
    "    accuracy, precision, recall, f1 = metrics\n",
    "    print(f\"{name} - Accuracy: {accuracy*100:.2f}%, Precision: {precision*100:.2f}%, Recall: {recall*100:.2f}%, F1 Score: {f1*100:.2f}%\")\n",
    "\n",
    "# Function for collecting user input and making predictions\n",
    "def user_predict_cgpa(model, scaler):\n",
    "    print(\"\\nPlease enter the following details to predict your CGPA:\")\n",
    "    \n",
    "    # Collecting user data (ensuring it matches feature names in training data)\n",
    "    # Updated user input collection (replace any mismatched keys)\n",
    "    user_data = {\n",
    "        'Student Age': int(input(\"Student Age (1: 18-21, 2: 22-25, 3: above 26): \")),\n",
    "        'Sex': int(input(\"Sex (1: female, 2: male): \")),\n",
    "        'High School Type': int(input(\"High School Type (1: private, 2: state, 3: other): \")),\n",
    "        'Scholarship': int(input(\"Scholarship (1: None, 2: 25%, 3: 50%, 4: 75%, 5: Full): \")),\n",
    "        'Additional Work': int(input(\"Additional Work (1: Yes, 2: No): \")),\n",
    "        'Artistic/Sports Activity': int(input(\"Artistic/Sports Activity (1: Yes, 2: No): \")),\n",
    "        'Partner': int(input(\"Partner (1: Yes, 2: No): \")),\n",
    "        'Total Salary': int(input(\"Total Salary (1: 135-200, 2: 201-270, 3: 271-340, 4: 341-410, 5: above 410): \")),\n",
    "        'Transportation': int(input(\"Transportation (1: Bus, 2: Car/Taxi, 3: Bicycle, 4: Other): \")),\n",
    "        'Accommodation': int(input(\"Accommodation (1: Rental, 2: Dormitory, 3: Family, 4: Other): \")),\n",
    "        'Mother’s Education': int(input(\"Mother's Education (1: primary, 2: secondary, 3: high school, 4: university, 5: MSc, 6: PhD): \")),\n",
    "        'Father’s Education': int(input(\"Father's Education (1: primary, 2: secondary, 3: high school, 4: university, 5: MSc, 6: PhD): \")),\n",
    "        'Siblings': int(input(\"Siblings (1: 1, 2: 2, 3: 3, 4: 4, 5: 5+): \")),\n",
    "        'Parental Status': int(input(\"Parental Status (1: married, 2: divorced, 3: died): \")),\n",
    "        'Mother’s Occupation': int(input(\"Mother's Occupation (1: retired, 2: housewife, 3: gov. officer, 4: private, 5: self-employed, 6: other): \")),\n",
    "        'Father’s Occupation': int(input(\"Father's Occupation (1: retired, 2: gov. officer, 3: private, 4: self-employed, 5: other): \")),\n",
    "        'Weekly Study Hours': int(input(\"Weekly Study Hours (1: None, 2: <5, 3: 6-10, 4: 11-20, 5: >20): \")),\n",
    "        'Non-Scientific Reading': int(input(\"Non-Scientific Reading (1: None, 2: Sometimes, 3: Often): \")),\n",
    "        'Scientific Reading': int(input(\"Scientific Reading (1: None, 2: Sometimes, 3: Often): \")),\n",
    "        'Seminar Attendance': int(input(\"Seminar Attendance (1: Yes, 2: No): \")),\n",
    "        'Impact of Projects': int(input(\"Impact of Projects (1: positive, 2: negative, 3: neutral): \")),\n",
    "        'Class Attendance': int(input(\"Class Attendance (1: always, 2: sometimes, 3: never): \")),\n",
    "        'Midterm 1 Prep': int(input(\"Midterm 1 Prep (1: alone, 2: friends, 3: n/a): \")),\n",
    "        'Midterm 2 Prep': int(input(\"Midterm 2 Prep (1: close to exam, 2: regular, 3: never): \")),\n",
    "        'Taking Notes': int(input(\"Taking Notes (1: never, 2: sometimes, 3: always): \")),\n",
    "        'Listening in Class': int(input(\"Listening in Class (1: never, 2: sometimes, 3: always): \")),\n",
    "        'Discussion Improves Success': int(input(\"Discussion Improves Success (1: never, 2: sometimes, 3: always): \")),\n",
    "        'Flip-Classroom': int(input(\"Flip-Classroom (1: not useful, 2: useful, 3: n/a): \")),\n",
    "    }\n",
    "\n",
    "    # Ensure user input is in DataFrame form and aligns with training columns\n",
    "    user_input_df = pd.DataFrame([user_data])\n",
    "\n",
    "    # Aligning DataFrame columns if necessary\n",
    "    missing_cols = [col for col in X.columns if col not in user_input_df.columns]\n",
    "    for col in missing_cols:\n",
    "        user_input_df[col] = 0\n",
    "\n",
    "    user_input_df = user_input_df[X.columns]  # Reorder columns to match training set\n",
    "\n",
    "    # Scale input\n",
    "    user_input_scaled = scaler.transform(user_input_df)\n",
    "\n",
    "    # Predict with the ensemble model\n",
    "    prediction = voting_ensemble.predict(user_input_scaled)\n",
    "    if prediction == 1:\n",
    "        print(\"\\nPrediction: Pass\")\n",
    "    else:\n",
    "        print(\"\\nPrediction: Fail\")\n",
    "\n",
    "        \n",
    "# Use the chosen model for final user prediction\n",
    "user_predict_cgpa(voting_ensemble, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cedab3-761b-4c92-9da8-929dfaa153f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
